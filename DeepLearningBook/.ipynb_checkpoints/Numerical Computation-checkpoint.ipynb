{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Computations\n",
    "\n",
    "Machine learning algorithms usually require a high amount of numerical computation. This typically refers to algorithms that solve mathematical problems by methods that update estimates of the solution via an iterative process, rather than an alytically deriving a formula to provide a symbolic expression for the correct solution.\n",
    "\n",
    "If you are familiar with following concepts you can skip this tutorial.\n",
    "\n",
    "> Reference : http://www.deeplearningbook.org/contents/numerical.html\n",
    "\n",
    "   1. Overﬂow and Underﬂow\n",
    "   2. Poor Conditioning\n",
    "   3. Gradient-Based Optimization\n",
    "   4. Constrained Optimization\n",
    "   5. Example: Linear Least Squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overﬂow and Underﬂow\n",
    "\n",
    "#### Underflow\n",
    "\n",
    "Underflow is refered to condition when a near to zero number is approximated as zero in numerical computaions. It is a type of rounding error.\n",
    "\n",
    "Many functions behave differently when argument is zero as compared to nearly zero argument.\n",
    "\n",
    "> Example: 10^(-325) <br> nearly zero term goes to zero\n",
    "\n",
    "\n",
    "#### Overflow\n",
    "\n",
    "Overflow is opposite of underflow it is refered to rounding of higher magnitudes to infinite.\n",
    "\n",
    "------------------------\n",
    "\n",
    "\n",
    "###    2. Poor Conditioning\n",
    "\n",
    "Conditioning refers to how rapidly a function changes with respect to small changesin its inputs. If the change is very high with small change in input can be problematic in scientific computation since even a small rounding error will lead to huge change in output.\n",
    "\n",
    "**Condition number:** In context of eigen decomposition of a real square matrix it is defined as :\n",
    "$$Cn = {max(eigen val) \\over min(eigen val)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "A = 10**-325\n",
    "print(\"The value 10^-325 is approximated as \") # underflow\n",
    "B = np.array([10.0**308])\n",
    "print(\"The value of 10^309 is approximated by numpy as\",B + 10**308)\n",
    "print(\"An Overflow error will come printed see below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient-Based Optimization\n",
    "\n",
    "Most deep-learning algorithm involves some kind of optimization in it.\n",
    "\n",
    "**$Optimization$ :** \n",
    "   - Task of minimization or maximization of some function f(x) by altering varibale x. Here, f(x) is called an ***objective function*** or ***criterion***, \n",
    "     while minimizing this is also referred as ***cost function***, ***loss function*** or ***error funciton***.\n",
    "\n",
    "we denote the argument to minimize f(x) by symbol **(*)** ==> **x* = arg min f(X)**\n",
    "\n",
    "**$Gradient$ :**\n",
    "\n",
    "If you are familier with calculus, we say if:\n",
    "$$y = f(x)$$\n",
    "then derivative of y with respect to x is the gradient / slope of y at x is:\n",
    "$$y' = f'(x) = {dy\\over dx}= {df(x)\\over dx}$$\n",
    "\n",
    "the derivative obtains the slope at a given point on y and hence shows us the direction to move x to minimize or maximize y.  And at a given extremum (minimum/maximum) the slope becomes zero ***f'(x) = 0*** which gives no direction since we have already reached the goal.\n",
    "\n",
    "Point's where ***f'(x) = 0*** are also called ***critical point*** or ***stationary point***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example gardient run this cell\n",
    "x = np.arange(-10,10,0.01)\n",
    "y = x**2 ## y = x^2\n",
    "dydx = 2*x ### slope of y obtained through calculus derivatives.\n",
    "\n",
    "### plotting\n",
    "plt.plot(x,dydx)\n",
    "plt.plot(x,y,\"-gs\",markevery=[x.shape[0]//2])\n",
    "plt.annotate('MINIMA', xy=(0,0), xytext=(0, 60),\n",
    "            arrowprops=dict(color='lightgreen', shrink=0.05),\n",
    "            )\n",
    "plt.annotate('SLOPE', xy=(-9.5,-15), xytext=(-10.5, 60),\n",
    "            arrowprops=dict(color='skyblue', shrink=0.005, width=1,headwidth=4),\n",
    "            )\n",
    "\n",
    "plt.annotate('y = f(x)', xy=(-9.7,99), xytext=(-5,100),\n",
    "            arrowprops=dict(color='green', shrink=0.005, width=1,headwidth=4),\n",
    "            )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice how slope is changing from negative value to positive value and is zero at minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maxima :** It is the highest point around it's neighbourhood.\n",
    "\n",
    "**Minima :** It is the lowest point around it's neighbour hood.\n",
    "\n",
    "**Saddle Point :** It's a point with zero slope but its niether a maxima nor a minima.\n",
    "\n",
    "**Local vs Global extremum's :** Global minima means lowest of all minima's for a given function in a given range. Similarily Global maxima means highest of all maxima for a given function in a given range.\n",
    "<div>\n",
    "<img src = \"num/mmsp.gif\" ><img src =\"num/glbl.png\" width=\"400px\"></div><center> The above graphs shows the meaning of minima, maxima, saddle, global extrema points.</center>\n",
    "\n",
    "<br>\n",
    "**Directional derivative :** The directional derivative in direction u (a unit vector) is the slope of the function f in direction u. In other words, the directional derivative is the derivative of the function f(x+αu) with respect to α, evaluated at α = 0.\n",
    "\n",
    "$${∂\\over∂α}f(x + αu) = u^T∇_xf(x)$$\n",
    "\n",
    "we can calculate this derivative around neighbourhood of x and minimum of these derivatives will be the steepest and fastest decreasing / minimizing path. \n",
    "\n",
    "> Reference for steepest descent  http://www.deeplearningbook.org/contents/numerical.html : page 83\n",
    "\n",
    "by locating the steepest gradient descent an iterative algorithm to move x is derived as follows:\n",
    "$$x_{i+1} = x_i− α .∇_xf(x)$$\n",
    "\n",
    "where, ***α*** is the ***learning rate***, a positive scalar determining the size of the step.<br>This algorithm is called ***method of steepest descent*** or ***Gradient Descent.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gardient Decsent:\n",
    "np.random.seed(1)\n",
    "# defintion of the criterion or objective function____ fx = x.sin(x)____\n",
    "def fx(x):\n",
    "    return(x*np.sin(x)) # after completion try changing this function\n",
    "\n",
    "# definition of derivative of objective function if you know calculus you will understand\n",
    "def del_fx(x):\n",
    "    dx = 0.01\n",
    "    dlfx = (fx(x + dx) - fx(x - dx)) / (2*dx) # derivative using first principal\n",
    "    return dlfx\n",
    "\n",
    "# gradient descent algorithm or method of steepest descent\n",
    "def gradient_descent(learning_rate,x):\n",
    "    delta_fx = 10**2\n",
    "    while(abs(delta_fx) > 0.001):\n",
    "        delta_fx = del_fx(x)\n",
    "        \n",
    "        ## YOUR CODE HERE\n",
    "        x = None ## update x using the update rule -->  x - learning_rate*delta_fx\n",
    "        #END\n",
    "        \n",
    "    return x\n",
    "    \n",
    "x = 5*np.random.rand()\n",
    "x_minima = gradient_descent(0.001,x)\n",
    "y_minima = fx(x_minima)\n",
    "X = np.arange(x_minima-10,x_minima+10,0.1)\n",
    "Y = fx(X)\n",
    "print(\"The minima found at :\",x_minima,\" with functional value of : \",y_minima)\n",
    "plt.plot(X,Y)\n",
    "plt.plot(x_minima,y_minima,'rs')\n",
    "plt.show()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected Output: <br>The minima found at : 4.91298375272  with functional value of :  -4.81446978887\n",
    "<img src = \"num\\gd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Beyond the Gradient: Jacobian and Hessian Matrices\n",
    " \n",
    "Sometimes we need to ﬁnd all the partial derivatives of a function whose input and output are both vectors. The matrix containing all such partial derivatives is known as a ***Jacobian matrix.***\n",
    "\n",
    "$${\\displaystyle \\mathbf {J} ={\\begin{bmatrix}{\\dfrac {\\partial \\mathbf {f} }{\\partial x_{1}}}&\\cdots &{\\dfrac {\\partial \\mathbf {f} }{\\partial x_{n}}}\\end{bmatrix}}={\\begin{bmatrix}{\\dfrac {\\partial f_{1}}{\\partial x_{1}}}&\\cdots &{\\dfrac {\\partial f_{1}}{\\partial x_{n}}}\\\\\\vdots &\\ddots &\\vdots \\\\{\\dfrac {\\partial f_{m}}{\\partial x_{1}}}&\\cdots &{\\dfrac {\\partial f_{m}}{\\partial x_{n}}}\\end{bmatrix}}}$$\n",
    "\n",
    "We are also sometimes interested in a derivative of a derivative. This is known as a ***second derivative.*** And these derivatives can be collected together into a matrix called the ***Hessian matrix***. The Hessian matrix **H(f)(x)** is deﬁned such that:\n",
    "\n",
    "$${\\mathbf  H}_{{i,j}}={\\frac  {\\partial ^{2}f}{\\partial x_{i}\\partial x_{j}}}.$$\n",
    "\n",
    "\n",
    "$${\\mathbf  H}={\\begin{bmatrix}{\\dfrac  {\\partial ^{2}f}{\\partial x_{1}^{2}}}&{\\dfrac  {\\partial ^{2}f}{\\partial x_{1}\\,\\partial x_{2}}}&\\cdots &{\\dfrac  {\\partial ^{2}f}{\\partial x_{1}\\,\\partial x_{n}}}\\\\[2.2ex]{\\dfrac  {\\partial ^{2}f}{\\partial x_{2}\\,\\partial x_{1}}}&{\\dfrac  {\\partial ^{2}f}{\\partial x_{2}^{2}}}&\\cdots &{\\dfrac  {\\partial ^{2}f}{\\partial x_{2}\\,\\partial x_{n}}}\\\\[2.2ex]\\vdots &\\vdots &\\ddots &\\vdots \\\\[2.2ex]{\\dfrac  {\\partial ^{2}f}{\\partial x_{n}\\,\\partial x_{1}}}&{\\dfrac  {\\partial ^{2}f}{\\partial x_{n}\\,\\partial x_{2}}}&\\cdots &{\\dfrac  {\\partial ^{2}f}{\\partial x_{n}^{2}}}\\end{bmatrix}}.$$\n",
    "\n",
    "Equivalently, the Hessian is the Jacobian of the gradient. Also anywhere that the second partial derivatives are continuous, the diﬀerential operators are commutative ==> that is, their order can be swapped :\n",
    "$${\\frac  {\\partial }{\\partial x_{i}}}\\left({\\frac  {\\partial f}{\\partial x_{j}}}\\right)={\\frac  {\\partial }{\\partial x_{j}}}\\left({\\frac  {\\partial f}{\\partial x_{i}}}\\right)$$\n",
    "\n",
    "This gives us a symmetric matrix H and we can decompose it into a set of real eigenvalues and an orthogonal basis of eigenvectors.  The second derivative in a speciﬁc direction represented by a unit vector **d** is given by **d<sup>T</sup>.H.d**.\n",
    "\n",
    "The (directional) second derivative tells us how well we can expect a gradient descent step to perform.<br> The second derivative can alse be used to determine whether a critical point is a local maximum, a local minimum, or a saddle point.\n",
    "   - f\"(x) > 0 ---> represents a minima\n",
    "   - f\"(x) < 0 ---> represents a maxima\n",
    "   - f\"(x) = 0 ---> represents a saddle point or straight-path\n",
    "   \n",
    "Let's see when can be hesiian matrix useful:\n",
    "\n",
    "We will make a 2-dimensional gradient descent function-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unguided Gradient Decent 2D\n",
    "# Defined Objective function\n",
    "def fx1x2(x1,x2):\n",
    "    return (2*x1**2 + 10*x2**2)\n",
    "\n",
    "def del_fxi(x1,x2): # defined gradient function / jacobian calculator\n",
    "    dx1 = 0.001\n",
    "    dx2 = 0.001\n",
    "    dfx1 = (fx1x2(x1+dx1,x2)-fx1x2(x1-dx1,x2))/(2*dx1)\n",
    "    dfx2 = (fx1x2(x1,x2+dx2)-fx1x2(x1,x2-dx2))/(2*dx2)\n",
    "    return dfx1, dfx2\n",
    "\n",
    "def gradient_ug(learning_rate,x1,x2): # gradinet descent function\n",
    "    cost = 1000\n",
    "    lst1 = np.array([x1])\n",
    "    lst2 = np.array([x2])\n",
    "    while(cost > 0.01):\n",
    "        dfx1, dfx2 = del_fxi(x1,x2)\n",
    "        \n",
    "        ## YOUR CODE HERE\n",
    "        x1 = None # update x1 using the update rule --> x1 - learning_rate*dfx1\n",
    "        x2 = None # update x2 using the update rule --> x2 - learning_rate*dfx2\n",
    "        lst1 = np.append(lst1,x1)\n",
    "        lst2 = np.append(lst2,x2)\n",
    "        \n",
    "        cost = None # calculate cost function using -->  fx1x2(x1,x2)\n",
    "        #END\n",
    "        \n",
    "    \n",
    "    return x1, x2, lst1, lst2\n",
    "\n",
    "x1 = 70\n",
    "x2 = 40\n",
    "\n",
    "x,y,l1,l2 = gradient_ug(0.085,x1,x2)\n",
    "    \n",
    "x1 = np.arange(x-100,x + 100,1)\n",
    "x2 = np.arange(x-50,x + 50,1)\n",
    "X, Y = np.meshgrid(x1, x2)\n",
    "fz = fx1x2(X,Y)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x,y,'ko')\n",
    "plt.plot(l1,l2,'-rx')\n",
    "plt.contour(X,Y,fz,20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected output: Motion of solution point with number of iteration on x1 x2 plane <img src = 'num/gd2d.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see using learning rate with gradient descent takes a lot of iterations and goes in zigzag motion since the diagonal value of hessian matrix are 5 times the other axis value.\n",
    "Which results in wastage of computation power for such a simple problem.\n",
    "\n",
    "This issue can be resolved by using information from the Hessian matrix to guide the search. The simplest method for doing so is known as ***Newton’s method.***\n",
    "\n",
    "Newton’s method is based on using a second-order Taylor series expansion to approximate f(x) near some point x(0), as:\n",
    "\n",
    "$$ x∗= x(0)− [H(f)(x(0))]^{−1}∇_{x}f(x(0))$$\n",
    "\n",
    "When f is a positive deﬁnite quadratic function, Newton’s method consists of applying above given equation only once to jump to the minimum of the function directly as you will see in below given program.\n",
    "\n",
    "Start writing Newton's Method ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guided Gradient Descent in single step (Newton's Method)\n",
    "# Defined Objective function\n",
    "def fx1x2(x1,x2):\n",
    "    return (2*x1**2 + 10*x2**2)\n",
    "\n",
    "def del_fxi(x1,x2): # defined gradient function / jacobian calculator\n",
    "    dx1 = 0.001\n",
    "    dx2 = 0.001\n",
    "    dfx1 = (fx1x2(x1+dx1,x2)-fx1x2(x1-dx1,x2))/(2*dx1)\n",
    "    dfx2 = (fx1x2(x1,x2+dx2)-fx1x2(x1,x2-dx2))/(2*dx2)\n",
    "    return dfx1, dfx2\n",
    "\n",
    "def newton(learning_rate,x1,x2): # Newton's method of gradient descent\n",
    "    cost = 1000\n",
    "    lst1 = np.array([x1])\n",
    "    lst2 = np.array([x2])\n",
    "    while(cost > 0.01):\n",
    "        dfx1, dfx2 = del_fxi(x1,x2)\n",
    "        H = hessian(x1,x2)\n",
    "        \n",
    "        ## YOUR CODE HERE\n",
    "        x1 = None # update x1 using the update rule --> x1 - (1/H[0,0])*dfx1\n",
    "        x2 = None # update x2 using the update rule --> x2 - (1/H[1,1])*dfx2\n",
    "        lst1 = np.append(lst1,x1)\n",
    "        lst2 = np.append(lst2,x2)\n",
    "        \n",
    "        cost = None # calculate cost function using -->  fx1x2(x1,x2)\n",
    "        #END\n",
    "        \n",
    "    \n",
    "    return x1, x2, lst1, lst2\n",
    "\n",
    "def hessian(x1,x2): # Hessian matrix calculator\n",
    "    dx1 = 0.001\n",
    "    dx2 = 0.001\n",
    "    dfx1mdx1, dfx1mdx2 = del_fxi(x1-dx1,x2)\n",
    "    dfx1pdx1, dfx1pdx2 = del_fxi(x1+dx1,x2)\n",
    "    dfx1x2md, dfx2x2md = del_fxi(x1,x2-dx1)\n",
    "    dfx1x2pd, dfx2x2pd = del_fxi(x1,x2+dx1)\n",
    "    df2x1x1 = (dfx1pdx1 - dfx1mdx1)/(2*dx1)\n",
    "    df2x2x2 = (dfx2x2pd - dfx2x2md)/(2*dx2)\n",
    "    df2x1x2 = (dfx1pdx2 - dfx1mdx2)/(2*dx1)\n",
    "    df2x2x1 = (dfx1x2pd - dfx1x2md)/(2*dx2)\n",
    "    \n",
    "    H = np.array([[df2x1x1,df2x1x2],[df2x2x1,df2x2x2]])\n",
    "    \n",
    "    return H\n",
    "    \n",
    "\n",
    "x1 = 70\n",
    "x2 = 40\n",
    "\n",
    "x,y,l1,l2 = newton(0.085,x1,x2)\n",
    "    \n",
    "x1 = np.arange(x-100,x + 100,1)\n",
    "x2 = np.arange(x-50,x + 50,1)\n",
    "X, Y = np.meshgrid(x1, x2)\n",
    "fz = fx1x2(X,Y)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x,y,'ko')\n",
    "plt.plot(l1,l2,'-rx')\n",
    "plt.contour(X,Y,fz,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected output : Motion of solution point with number of iteration on x1 x2 plane <img src='num/newton.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization algorithms that use only the gradient, such as gradient descent, are called ***ﬁrst-order optimization algorithms***. Optimization algorithms that also use the Hessian matrix, such as Newton’s method, are called ***second-order optimization algorithms.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Constrained Optimization\n",
    "\n",
    "Sometimes we wish not only to maximize or minimize a function f(x) over all possible values of x. Instead we may wish to ﬁnd the maximal or minimal value of f(x) for values of x in some set S. This is known as ***constrained optimization***. Points x that lie within the set S are called feasible points in constrained optimization terminology.\n",
    "\n",
    "A Simple Example:\n",
    "$${\\displaystyle \\min f({\\mathbf {x}})=x_{1}^{2}-3x_{2}^{4}}$$ contraints, $${\\displaystyle x_{1}\\geq 1}-->[in\n",
    "equality-constraint],\\\\{\\displaystyle x_{2}=1-->[equality-constraint]}$$\n",
    "\n",
    "One simple approach to these type of problems will be to incorporate the contraints in your gradient descent optimizer.\n",
    "\n",
    "A more sophisticated approach is to design a diﬀerent, unconstrained optimization problem whose solution can be converted into a solution to the original, constrained optimization problem.\n",
    "\n",
    "For Exmaple:<br>\n",
    "  - For above given problem x1 and x2 can be converted as **x1 = u ,x2 = 1** and **g(x) = |u<sup>2</sup> - 3|**, now we can minimize g(x) which is an unconstrained form of f(X) and return the solution as **(u,1)**.\n",
    "    This approach requires creativity, the transformation between optimization problems must be designed speciﬁcally for each case we encounter.\n",
    "    \n",
    "#### Karush–Kuhn–Tucker Approach\n",
    "\n",
    "The Karush–Kuhn–Tucker(KKT) approach provides a very general solution to constrained optimization. KKT uses generalised Lagrange function for this purpose:\n",
    "\n",
    "We define set of x S as :\n",
    "$$S=\\{x\\|\\ ∀i, g^{(i)}(x) = 0 , ∀j, h^{(j)}(x)≤0\\}$$<br>\n",
    "where (h<=0) and (g=0) are inequality and equality continously differentiable constraints over x*. Now we introduce new variables λ<sub>i</sub> and α<sub>j</sub> for each constraint, these are called the KKT multipliers and finally we define the Lagrange function as follows:\n",
    "\n",
    "$$L(x, λ, α) = f(x) +\\sum_iλ_ig^{(i)}(x) +\\sum_jα_jh^{(j)}(x)$$\n",
    "\n",
    "Now we can define our unconstrained equation to follow:\n",
    "\n",
    "$$min_xmax_λmax_{α,α≥0}\\ L(x, λ, α)$$\n",
    "\n",
    "You can see that due to maximaization over λ, α:\n",
    "\n",
    "$$max_λmax_{α,α≥0}L(x, λ, α) = f(x),\\text{ if contraints are satisfied}\\\\max_λmax_{α,α≥0}L(x, λ, α) = ∞,\\text{contraints are not satisfied}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Example: Linear Least Squares\n",
    "\n",
    "Suppose we want to ﬁnd the value of x that minimizes using gradient optimizer:\n",
    "$$f(x) ={1\\over2}||Ax − b||^2.$$\n",
    "First, we need to obtain the gradient or derivative:\n",
    "$$∇_xf(x) = A^T(Ax − b) = A^TAx − A^Tb.$$\n",
    "\n",
    "----------------\n",
    "***Algorithm 1:*** Gradient Descent\n",
    "\n",
    "Already discussed\n",
    "\n",
    "----------------\n",
    "\n",
    "With constraint that x<sup>T</sup>x <= 1\n",
    "\n",
    "***Algorithm 2:*** KKT\n",
    "\n",
    "$$L(x, λ) = f(x) + λ( x^Tx − 1)$$\n",
    "\n",
    "to minimize derivative of L with repect to x should go to zero:\n",
    "\n",
    " $$A^TAx − A^Tb + 2λx = 0\\\\x = (A^TA + 2λI)^{−1}A^Tb.$$\n",
    " \n",
    " The magnitude of λ must be chosen such that the result obeys the constraint. We can ﬁnd this value by performing gradient ascent on λ. To do so, observe :\n",
    " \n",
    " $${∂\\over∂λ}L(x, λ) = x^Tx − 1$$\n",
    " \n",
    " When the norm of x exceeds 1, this derivative is positive, so to follow the derivative uphill and increase the Lagrangian with respect to λ, we increase λ. Because the coeﬃcient on the x<sup>T</sup>x penalty has increased, solving the linear equation for x will now yield a solution with a smaller norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Least Square using KKT\n",
    "A = np.array([1,1])\n",
    "b = 4\n",
    "## define fx\n",
    "def fx(X):\n",
    "    f = 0.5*np.square(np.dot(A,X) - b)\n",
    "    return f\n",
    "\n",
    "## define x through inverse matrix multiplication\n",
    "def inv_x(X, lmd):\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    v = None # find dot product of A.T and A use ---> v = np.dot(A.T,A) \n",
    "    i = None # find the matrix to inverse in above derivation for kkt use ---> i = 1/(v + 2*lmd)\n",
    "    d = None # use ---> np.dot(i ,A.T*b)\n",
    "    #END\n",
    "    \n",
    "    \n",
    "    return d\n",
    "\n",
    "## define lagrangeon\n",
    "def Lg(X, lmd):\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    L = None # define the lagrangeon use ---> L = fx(X) + lmd*(np.dot(X.T,X) - 1)\n",
    "    #END\n",
    "    \n",
    "    return L\n",
    "\n",
    "## define Lagrangeon derivative \n",
    "def dLg(X):\n",
    "    return(np.dot(X.T,X) - 1)\n",
    "\n",
    "## define KKT solver\n",
    "def kkt(x,lmd):\n",
    "    oldCost = Lg(x,lmd)\n",
    "    cost = 0\n",
    "    dcost = 10\n",
    "    dl = 10\n",
    "    lst = [np.squeeze(x)]\n",
    "    while (dcost > 1e-15 or dl > 1e-15):\n",
    "        x = inv_x(x,lmd)\n",
    "        cost = Lg(x,lmd)\n",
    "        dcost = cost - oldCost\n",
    "        oldCost = cost\n",
    "        dl = dLg(x)\n",
    "        \n",
    "        ## YOUR CODE HERE\n",
    "        lmd = None # increase the lambda by some multiple od dl use ---> lmd = lmd + dl\n",
    "        #END\n",
    "        \n",
    "        lst.append(np.squeeze(x))\n",
    "    return x, np.array(lst)\n",
    "\n",
    "Xa = np.array([[3],[2]])\n",
    "Xd, lst = kkt(Xa,0.01)\n",
    "x1 = np.arange(Xd[0]-3,Xd[0]+3,0.01)\n",
    "x2 = np.arange(Xd[1]-3,Xd[1]+3,0.01)\n",
    "X, Y = np.meshgrid(x1, x2)\n",
    "t = X.reshape(X.shape[0]*X.shape[1])\n",
    "q = Y.reshape(Y.shape[0]*Y.shape[1])\n",
    "fz = fx(np.array([t,q]))\n",
    "dz = (X**2 + Y**2)<1\n",
    "Z = fz.reshape(X.shape[0],X.shape[1])\n",
    "print(\"The yellow circle is contraint line \")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.contour(X,Y,dz)\n",
    "plt.plot(lst[:,0],lst[:,1],'-kx')\n",
    "plt.contour(X,Y,Z,80)\n",
    "plt.plot(Xd[0],Xd[1],'-r*')\n",
    "plt.show()\n",
    "print(\"The optimized solution is \", Xd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> Expected output:<img src=\"num/lg.png\">The optimized solution is  [ 0.70710678  0.70710678]\n",
    "\n",
    "As you can see the overshoot competetion between x and lambda is going on to reach optimization. And finally it reaches on the edge of the constraint boundary which is correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">** Congratulation on completing this tutorial you are doing very well. In the next part we will start the main thing from machine learning basics.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
