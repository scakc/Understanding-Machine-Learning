{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "\n",
    "If you are familier with following concepts you can move to next notebook:\n",
    "\n",
    "> Reference : http://www.deeplearningbook.org/contents/ml.html\n",
    "\n",
    "    1. Learning Algorithms\n",
    "    2. Capacity, Overﬁtting and Underﬁtting\n",
    "    3. Hyperparameters and Validation Sets\n",
    "    4. Estimators, Bias and Variance\n",
    "    5. Maximum Likelihood Estimation\n",
    "    6. Bayesian Statistics\n",
    "    7. Supervised Learning Algorithms\n",
    "    8. Unsupervised Learning Algorithms\n",
    "    9. Stochastic Gradient Descent\n",
    "    10. Building a Machine Learning Algorithm\n",
    "    11. Challenges Motivating Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is a speciﬁc kind of machine learning. To understand deep learning well, one must have a solid understanding of the basic principles of machine learning. This tutorial provides a brief course in the most important general principles that are applied throughout the rest of the book.\n",
    "\n",
    "### 1. Learning Algorithms\n",
    "\n",
    "*A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experienceE.*\n",
    "\n",
    "#### 1.1 Task, *T*\n",
    "\n",
    "The objective of the learning is to perform tasks better and faster than other programs and humans. So task is any particular function we want our ML program to be able to do.\n",
    "\n",
    "Few common ML tasks include:\n",
    "   - **Classification**: In this type of task, the computer program is asked to specify which of k categories some input                               belongs to.\n",
    "   \n",
    "   - **Classification with missing inputs**: Many times part of inputs are not known and we need to classify them without those inputs using some fucntion this type of problem generally arises in medical situations.\n",
    "   \n",
    "   - **Regression**: In this type of task, the computer program is asked to predict a numerical value given some input.\n",
    "   \n",
    "   - **Transcription**: In this type of task, the machine learning system is asked to observe a relatively unstructured representation of some kind of data and transcribe the information into discrete textual form. For example,optical character recognition.\n",
    "   \n",
    "   - **Machine Translation**: In a machine translation task, the input already consists of a sequence of symbols in some language, and the computer program must convert this into a sequence of symbols in another language. \n",
    "   \n",
    "   - **Structure output**: Structured output tasks involve any task where the output is a vector (or other data structure containing multiple values) with important relationships between the diﬀerent elements.\n",
    "   \n",
    "   - **Anamoly Detection**: In this type of task, the computer program shifts through a set of events or objects and ﬂags some of them as being unusual or atypical.\n",
    "   \n",
    "   - ** Synthesis and sampling**: In this type of task, the machine learning algorithm is asked to generate new examples that are similar to those in the training data.\n",
    "   \n",
    "   - **Imputation of missing Values**: This type task are set to predict the missing values from a given example.\n",
    "   \n",
    "   - **Denoising**: Conversion of corrupted input to original input\n",
    "   \n",
    "   - **Density Estimation**: To learn a function that can be used as a probabilty density function..           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "# classification example in general programing function:\n",
    "def classify(a): # classifies the even and odd numbers\n",
    "    if (a%2 == 0):\n",
    "        return \"Class Even\"\n",
    "    elif(a%2 == 1):\n",
    "        return \"Class Odd\"\n",
    "    else:\n",
    "        return \"Undefined Class\"\n",
    "    \n",
    "    \n",
    "\n",
    "data = 0.02\n",
    "try:\n",
    "    data = int(input(\"Enter a number: \"))\n",
    "except ValueError:\n",
    "    pass\n",
    "    \n",
    "print(\"The number Entered is in: \",classify(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Performance Measure: *P*\n",
    "\n",
    "To evaluate the abilities of a machine learning algorithm, we must design a quantitative measure of its performance.\n",
    "Usually this performance measure P is speciﬁc to the task T being carried out by the system.\n",
    "\n",
    "Many tasks like clasification, regresion etc can be measured in terms of **accuracy, error rate** but not all of then can be measure like this there are task like density estimation for which the accuracy calculation would be meaning less. It's easy to measure a particaular thing but it's difficult to decide what to be measured in order to achieve the required task.\n",
    "\n",
    "\n",
    "#### 1.3 Experience: *E*\n",
    "\n",
    "Machine learning algorithms can be broadly categorized as unsupervised or supervised by what kind of experience they are allowed to have during the learning process.\n",
    "\n",
    "***Unsupervised Learning***: Each experience or training sample is a set of features to learn properties from.\n",
    "\n",
    "***Supervised Learning***: Each experience is a set of features associated with a lable.\n",
    "\n",
    "Machine learning is similar to human learning and so categorized as given above.\n",
    "Unsupervised learning is like person observing several things and making a conclusion or a theory or picture based on just the inputs, whereas Supervised learning is like teaching someone that this is a cat, this is a knife like we were thaught in schools where cats and knifes were labels.\n",
    "\n",
    "#### 1.4 Example Linear Regression:\n",
    "\n",
    "As the name indicates it is used to perform regression. It is a supervised learning problem.\n",
    "\n",
    "**Objective**:\n",
    "To build a system that can take a vector x ∈ R<sup>n</sup> as input and predict the value of a scalar y ∈ R as its output. The output of linear regression is a linear function of the input. Let y' be the value that our model predicts y should take on. We deﬁne the output to be a linear equation as follows:\n",
    "\n",
    "$$y' = w^T.x + b\\\\\n",
    "\\Longrightarrow y' = [b,\\ w]^T.[1,\\ x]\\\\\n",
    "\\Longrightarrow y' = w_{new}^T.x_{new}\n",
    "$$\n",
    "\n",
    "where, w is vector of **parameters**. <br> Now we have our ***task: to predict y'***\n",
    "\n",
    "We will define two sets \n",
    "1. train set (to train our model)\n",
    "2. test set (to test our model)\n",
    "\n",
    "we now have to define a performance measure, we can measure mean squared error here as:\n",
    "\n",
    "$$MSE={1\\over m}\\sum_i(y'− y)^2_i.$$\n",
    "\n",
    "you might notice when y'--> y <==> MSE --> 0\n",
    "\n",
    "One way of solving such problem could be gradient descent but we will go with a more mathematical approach here which will give result in one step. we say to minimize MSE:\n",
    "\n",
    "$$say\\ the\\ model\\ is:\\ ( y' = w.x)\\\\\n",
    "\\Longrightarrow \\triangledown_w MSE_{train} = 0\\\\\n",
    "\\Longrightarrow{1\\over m}\\triangledown_w\\|y'-y\\|^2_2=0\\\\\n",
    "\\Longrightarrow{\\triangledown_w(x.w-y)^T(x.w-y)=0}\\\\\n",
    "\\Longrightarrow w = (x^Tx)^{-1}x^T.y$$\n",
    "\n",
    "\n",
    "The system of equation solved by this equation are called normal equations.\n",
    "\n",
    "Lets try it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression:\n",
    "# we are going to find a line that minimized the error of y' and y in a given distrubition\n",
    "np.random.seed(1)\n",
    "def regress(x,y):\n",
    "    xnew = np.append(np.ones(x.shape),x,axis=1)\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    xtx = None # find xT.x of normal equation solver use--> np.dot(xnew.T,xnew)\n",
    "    # finding inverse of xtx\n",
    "    try:\n",
    "        xtx_inv = np.linalg.inv(xtx)\n",
    "    except:\n",
    "        xtx_inv = 1/xtx\n",
    "        \n",
    "    xty = None # find the XTy of th equation use --> np.dot(xnew.T,y)\n",
    "    wnew = None # find the parametres using -->  np.dot(xtx_inv,xty)\n",
    "    #END\n",
    "    \n",
    "    w = wnew[1]\n",
    "    b = wnew[0]\n",
    "    return w, b\n",
    "\n",
    "x = np.random.randn(100,1)\n",
    "y = np.random.randn(100,1)**3\n",
    "w, b = regress(x,y)\n",
    "yd = w*x + b\n",
    "\n",
    "print(\"The figure denotes a regression line approximating the y with x\")\n",
    "plt.plot(x,yd,'-r')\n",
    "plt.plot(x,y,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected output :<br>\n",
    "    The figure denotes a regression line approximating the y with x\n",
    " <img src=\"mlb/regression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Capacity, Overﬁtting and Underﬁtting\n",
    "\n",
    "The central challenge in machine learning is that our algorithm must perform well on new, previously unseen inputs and not just those on which our model was trained. The ability to perform well on previously un observed inputs is called ***generalization***.\n",
    "\n",
    "*training set* : dataset on which the learning model is trained.\n",
    "\n",
    "*test set*: dataset on which model is tested.\n",
    "\n",
    "we generally train model by minimizing training_error whereas, we actually care more about test_error.\n",
    "\n",
    "It is important to note that test data should come from same distribution as that of training data. otherwise the model will not be applicable to such examples and you might end up getting very low performance.\n",
    "\n",
    "The performance of a learning algorithm is determined by its ability to:\n",
    "    1. Make the training error small.\n",
    "    2. Make the gap between training error and test error small.\n",
    "\n",
    "These two factors correspond to the two central challenges in machine learning:\n",
    "\n",
    "   - *underfitting*: occurs when the model is not able to obtain a suﬃciently low error value on the training set.\n",
    "   - *overfitting* : occurs whenthe gap between the training error and test error is too large.\n",
    "   \n",
    "We can control whether a model is more likely to overﬁt or underﬁt by altering it's **capacity.**  Informally, a model’s capacity is its ability to ﬁt a wide variety of functions. \n",
    "\n",
    "Models with low capacity may struggle to ﬁt the training set. Models with high capacity can overﬁt by memorizing properties of the training set that do not serve them well on the test set.\n",
    "\n",
    "One way to control the capacity of a learning algorithm is by choosing it's hypothesis space, the set of functions that the learning algorithm is allowed to select as being the solution.\n",
    "\n",
    "> Example: the linear regression algorithm has the set of all linear functions of its input as its hypothesis space.\n",
    "\n",
    "Say we want to expand the linear regression model to more hypothesis spaces like quadratic,cubic,other polynomial forms.\n",
    "\n",
    "For quadratic function, \n",
    "we can use x<sup>2</sup> as new dimensional parameters.\n",
    "\n",
    ">Let's see this in below example:\n",
    "   -Try changing the value of n in the polynomial regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell..............................................\n",
    "# Regression analysis\n",
    "np.random.seed(1)\n",
    "# read this function it is similar to the linear regression we discussed earlier.......\n",
    "def poly_regress(x,y,n):\n",
    "    xnew = x**0\n",
    "    #In below 2 lines we are basically increasing the dimension of input from {x}-->y to {x,x^2,x^3,...,x^n}-->y\n",
    "    for i in range(1,n+1):\n",
    "        xnew = np.append(xnew,x**i,axis=1)\n",
    "    \n",
    "    # rest of the code is same.........................\n",
    "    xtx = np.dot(xnew.T,xnew)\n",
    "    try:\n",
    "        xtx_inv = np.linalg.inv(xtx)\n",
    "    except:\n",
    "        xtx_inv = 1/xtx\n",
    "        \n",
    "    xty = np.dot(xnew.T,y)\n",
    "    wnew = np.dot(xtx_inv,xty)\n",
    "    \n",
    "    return wnew\n",
    "\n",
    "def calc_output(x,w,n):\n",
    "    yd = 0\n",
    "    for i in range(n+1):\n",
    "        yd = yd + (w[i,:]*(x**i))\n",
    "    return yd\n",
    "        \n",
    "\n",
    "x = np.arange(0,15,0.15).reshape(100,1)\n",
    "x_train = x[0:70]\n",
    "y = x**2 + 5*np.random.randn(100,1)\n",
    "y_train = y[0:70]\n",
    "\n",
    "# Linear \n",
    "w_l = poly_regress(x_train,y_train,1)\n",
    "yd_l = calc_output(x,w_l,1)\n",
    "\n",
    "# Quadratic\n",
    "w_q = poly_regress(x_train,y_train,2)\n",
    "yd_q = calc_output(x,w_q,2)\n",
    "\n",
    "# Polynnomial\n",
    "w_p = poly_regress(x_train,y_train,5)\n",
    "yd_p = calc_output(x,w_p,5) # Try different values of n to see behaviour\n",
    "\n",
    "print(\"The figure denotes a regression line approximating the y with x\")\n",
    "\n",
    "f, ax = plt.subplots(1,3,figsize=[16,4])\n",
    "ax[0].axvspan(0, x[70], color='0.1', alpha=0.1)\n",
    "ax[0].plot(x,yd_l,'k.')\n",
    "ax[0].plot(x,y,'.')\n",
    "ax[0].set_title(\"n = 1 (Linear) Underfitting\")\n",
    "ax[0].annotate('train', xy=(2, 150) )\n",
    "ax[0].annotate('test', xy=(12, 0) )\n",
    "ax[1].axvspan(0, x[70], color='0.1', alpha=0.1)\n",
    "ax[1].plot(x,yd_q,'k.')\n",
    "ax[1].plot(x,y,'.')\n",
    "ax[1].set_title(\"n = 2 (Quadratic) Optimal fit\")\n",
    "ax[1].annotate('train', xy=(2, 150) )\n",
    "ax[1].annotate('test', xy=(12, 0) )\n",
    "ax[2].axvspan(0, x[70], color='0.1', alpha=0.1)\n",
    "ax[2].plot(x,yd_p,'k.')\n",
    "ax[2].plot(x,y,'.')\n",
    "ax[2].set_title(\"n = 5 Overfitting\")\n",
    "ax[2].annotate('train', xy=(2, 150) )\n",
    "ax[2].annotate('test', xy=(12, 0) )\n",
    "plt.show()\n",
    "print(\"The shaded part represents the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Conclusion: As you can see that the linear function is unable to capture the curvature so it underfits the data and quadractic function is optimal for the dataset but as we go on increasing the polynomial power the model captures unnecessary curvatures due to its complexity in nature and so it overfits the training dataset and fails on test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Parametric models**: Models that learn from a vector that have a fixed or finite size before any data is observed.\n",
    "\n",
    "**Non-parammetric models**: Models that is not bounded by size before reading the dataset is called non-parameteric models.\n",
    "\n",
    "**Bayes error**: Error incurred by making the predictions from true distribution function is called Byes error. You can say it is like a noise or the minimum training error any algorithm can achieve if any algorithm is getting less than this error that means that the model is overfiting the data.\n",
    "\n",
    "For example in before example we made regression models lets see how there error changes with respect to the training data size. and we know the bayes error since we know that the data is of what degree polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before running this cell make sure you run above cell.\n",
    "# run this cell to see variation of errors with respect to training size.\n",
    "np.random.seed(1)\n",
    "x = np.arange(0,15,0.15).reshape(100,1)\n",
    "y = x**2 + 5*np.random.randn(100,1)\n",
    "bayes_err = np.sum(abs(x**2-y))/x.shape[0]\n",
    "print(\"The bayes error is :\",bayes_err)\n",
    "\n",
    "elst = []\n",
    "for i in range(50,92):\n",
    "    n1 = 2\n",
    "    n2 = 3\n",
    "    \n",
    "    \n",
    "    x_tr = x[0:i]\n",
    "    x_te = x[i:]\n",
    "    y_tr = y[0:i]\n",
    "    y_te = y[i:]\n",
    "    w_q = poly_regress(x_tr,y_tr,n1)\n",
    "    w_p = poly_regress(x_tr,y_tr,n2)\n",
    "    \n",
    "    yd_q_tr = calc_output(x_tr,w_q,n1)\n",
    "    yd_q_te = calc_output(x_te,w_q,n1)\n",
    "    yd_p_tr = calc_output(x_tr,w_p,n2)\n",
    "    yd_p_te = calc_output(x_te,w_p,n2)\n",
    "    \n",
    "    err_q_tr = np.sum(abs(yd_q_tr-y_tr))/y_tr.shape[0]\n",
    "    err_q_te = np.sum(abs(yd_q_te-y_te))/y_te.shape[0]\n",
    "    err_p_tr = np.sum(abs(yd_p_tr-y_tr))/y_tr.shape[0]\n",
    "    err_p_te = np.sum(abs(yd_p_te-y_te))/y_te.shape[0]\n",
    "    \n",
    "    err = np.array([err_q_tr,err_q_te,err_p_tr,err_p_te])\n",
    "    elst.append(err)\n",
    "\n",
    "xaxis = np.arange(50,92)\n",
    "edata = np.array(elst)\n",
    "bayes = (np.ones((edata.shape[0],1)))*bayes_err\n",
    "f, ax = plt.subplots(1,2,figsize=[16,4])\n",
    "ax[0].plot(xaxis,edata[:,0],'-g', label='quadratic-n1')\n",
    "ax[1].plot(xaxis,edata[:,1],'-g', label='quadratic-n1')\n",
    "ax[0].plot(xaxis,edata[:,2],'-b', label='n2-poly')\n",
    "ax[1].plot(xaxis,edata[:,3],'-b', label='n2-poly')\n",
    "ax[0].set_xlabel(\"Training size\")\n",
    "ax[1].set_xlabel(\"Training size\")\n",
    "ax[0].set_ylabel(\"Training Error\")\n",
    "ax[1].set_ylabel(\"Test Error\")\n",
    "ax[0].plot(xaxis,bayes,'--y', label='bayes err')\n",
    "ax[1].plot(xaxis,bayes,'--y', label='bayes err')\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">You will notice that the test error or generalization error decreases with increase in number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 The No Free Lunch Theorem\n",
    "\n",
    "The no free lunch theorem for machine learning states that, averaged over all possible data-generating distributions, every classiﬁcation algorithm has the same error rate when classifying previously unobserved points. In other words,in some sense, no machine learning algorithm is universally any better than any other. The most sophisticated algorithm we can conceive of has the same average performance (over all possible tasks) as merely predicting that every point belongs to the same class.\n",
    "\n",
    "Fortunately, these results hold only when we average over all possible data-generating distributions. If we make assumptions about the kinds of probability distributions we encounter in real-world applications, then we can design learning algorithms that perform well on these distributions.\n",
    "\n",
    "\n",
    "#### 2.2  Regularization\n",
    "Given a distribution we dont know what the actual distribution looks like so we have to some how avoid overfitting for higher degree of hypothesis space also. we call this using regularization. for example -\n",
    "\n",
    "while using a gradient desccent / weight decay (discussed in previous tutorial.) method for solving a regression model we minimize the cost function which consist of two terms:-\n",
    "    - Mean squared error over training set.\n",
    "    - Regularization term.\n",
    "\n",
    "you can see for a n-variabled polynomial regression there are n (w's) in parameter list and if we control the magnitude of these (w's) we can reduce the effect of overfitting curvatures in our model.\n",
    "\n",
    "So the cost function form which we use in such approach is:\n",
    "    \n",
    "$$J(w) = MSE_{train} + \\lambda w^Tw$$\n",
    "\n",
    "By controlling ***lambda*** we can decrease or increase the effect of overfitting and underfitting. Due to ***optimization*** of cost function the prenscence of regulization term tries to ***reduce magnitude of w's***. the reduction is a parameter of lambda. If the amount of reduction ***i.e lambda value is very high the model will go into high underfiiting or high bias mode.***\n",
    "\n",
    "The term ***high bias*** means highly depending on the bias term ***b*** in our model ***y' = w<sup>T</sup>x + b***.\n",
    "\n",
    "Note that we need not regularize bias b since its not affecting the curvature only the offset.\n",
    "\n",
    "Let's run the gradient descent model with different regularization parameters.......\n",
    "\n",
    "> Please read the function used below to get a understanding of how gradient descent in regression works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularization run this cell\n",
    "np.random.seed(5)\n",
    "\n",
    "# The cost function\n",
    "def cost_f(yd,y,w,ld):\n",
    "    mse = 0.5*np.dot((yd-y),(yd-y).T)/y.shape[1]\n",
    "    reg = ld*np.dot(w.T,w)\n",
    "    c = mse + reg\n",
    "    return c\n",
    "\n",
    "# The differential of cost function with respect to w's and b's\n",
    "def d_cost_f(yd,y,x,w,ld):\n",
    "    m = y.shape[1]\n",
    "    dfdw = (1/m)*np.dot((yd-y),x.T).T + 2*ld*w\n",
    "    dfdb = (1/m)*np.sum((yd-y))\n",
    "    \n",
    "    return dfdw, dfdb\n",
    "\n",
    "# The Regression model.....\n",
    "def g_regression(x1,y,learning_rate,ld,n):\n",
    "    x = x1\n",
    "    #In below 2 lines we are basically increasing the dimension of input from {x}-->y to {x,x^2,x^3,...,x^n}-->y\n",
    "    for i in range(2,n+1):\n",
    "        x = np.append(x,x1**i,axis=0)\n",
    "    \n",
    "    w = np.random.randn(x.shape[0],1)\n",
    "    b = np.random.randn(1,1)\n",
    "    yd = np.dot(w.T,x) + b\n",
    "    dcost = 10\n",
    "    ocost = 0\n",
    "    while(abs(dcost) > 0.00000001):\n",
    "        dw, db = d_cost_f(yd,y,x,w,ld)\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        yd = np.dot(w.T,x) + b\n",
    "        cost = cost_f(yd,y,w,ld)\n",
    "        dcost = cost - ocost\n",
    "        ocost = cost\n",
    "        \n",
    "    return w, b\n",
    "\n",
    "# The prediction over testing set......\n",
    "def calc(x1,y,w,b,n):\n",
    "    x = x1\n",
    "    #In below 2 lines we are basically increasing the dimension of input from {x}-->y to {x,x^2,x^3,...,x^n}-->y\n",
    "    for i in range(2,n+1):\n",
    "        x = np.append(x,x1**i,axis=0)\n",
    "    yd = np.dot(w.T,x) + b\n",
    "    return yd\n",
    "\n",
    "n = 5 #hypothesis space / polyomial degree\n",
    "ts = 60 # traning size\n",
    "x = (np.arange(0,1.5,0.015)).reshape(1,100) # input random variable\n",
    "x_train = x[0,0:ts].reshape(1,ts) # training input\n",
    "y = (x**2 + 0.1*np.random.randn(1,100)).reshape(1,100) # output random variable\n",
    "y_train = y[0,0:ts].reshape(1,ts) # training output\n",
    "\n",
    "ys = x**2 # initialization of predicted values with true distribution.\n",
    "cost = []\n",
    "\n",
    "lds = np.array([0,0,0.005,0.012,0.02,0.05,0.1,0.2,0.5,0.6,0.7,0.8,1,5,10])  # lambda values to test\n",
    "\n",
    "# iterating over lamda's\n",
    "for ld in lds[1:]:\n",
    "    print(\"computing for lambda:\", ld,\"...\")\n",
    "    w, b = g_regression(x_train,y_train,0.0005,ld,n)\n",
    "    yd = calc(x,y,w,b,n)\n",
    "    ys = np.append(ys,yd,axis=0)\n",
    "    cost.append(cost_f(yd,y,w,ld))\n",
    "\n",
    "npt = ys.shape[0]//3\n",
    "f, ax = plt.subplots(npt,3,figsize=[16,20])\n",
    "\n",
    "# plotting the predictions/.....................................\n",
    "for i in range(npt):\n",
    "    for j in range(3):\n",
    "        ax[i,j].plot(ys[min(i*3 + j,ys.shape[0]-1),:].T,'.k')\n",
    "        ax[i,j].plot(y.T,'.g')\n",
    "        ax[i,j].set_title(\"n = \"+str(min(n,2+(i+j)*20))+\",lambda = \"+str(lds[i*3 + j]))\n",
    "        ax[i,j].annotate('train', xy=(20, 2) )\n",
    "        ax[i,j].annotate('test', xy=(80, 0) )\n",
    "        ax[i,j].axvspan(0, ts, color='0.1', alpha=0.1)\n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> you will notice as we increase lambda the model goes from overfitting to underfiiting and some where in middle we obtain regularized optimum solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Hyperparameters and Validation Sets\n",
    "\n",
    "Most machine learning algorithms have hyperparameters, settings that we canuse to control the algorithm’s behavior. Typically these are the variables that the algorithms does not adapt it-self.\n",
    "\n",
    ">Example: learning_rate, lambda(regulization), hypothesis space etc.\n",
    "\n",
    "we can make algorithms to optimize hyperparameters but optimizing them based on training set will only result in overfitting and the generalization gap(error gap between training and test set) will increase.\n",
    "\n",
    "To solve this problem we introduce a new set called:<br>\n",
    "***Validation set***: A part of training set not used for training parameters but for calculating the generalization gap and optimizing the hyper-parameters. It's like a test set but not used for testing the optimized model, but used to optimize the model hyper-parameters.\n",
    "\n",
    "Considering all sets we now have three sets of data : training set, validation set, test set. Usually the percentage given to these three categories in most general algorithms is about 80%-96%,2%-10%,2%-10% of whole dataset respectively.\n",
    "\n",
    "#### 3.1 Cross - Validation\n",
    "\n",
    "In this method the dataset is divided into k non-overlaping subsets and test error is calculted by taking average over all the test errors. On i<sup>th</sup> trial the i<sup>th</sup> subset is used as the test set and reamining as training set this is genrally used when the dataset size is small and there is scarcity of data. This is also known as ***k-fold cross validation set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Estimators, Bias and Variance\n",
    "\n",
    "#### 4.1 Point Estimation\n",
    "\n",
    "Point estimation is the attempt to provide the single “best” prediction of some quantity of interest. In general the quantity of interest can be a single parameter or a vector of parameters in some parametric model, such as the weights in our linear regression example, but it can also be a whole function.\n",
    "\n",
    "For example say we have {x1,x2,....,xn} indepedent and identically disributed datasets. \n",
    "\n",
    "A point estimator or statistic is any function of the data is given by:\n",
    "\n",
    "$$\\theta_m = g(x^{(1)},x^{(2)},....,x^{(n)})$$\n",
    "\n",
    "While any function can be considered as an estimator, a good estimator is a function whose output is close to the true underlying θ that generated the training data.\n",
    "\n",
    "Point estimation can also refer to the estimation of the relationship between input and target variables. We refer to these types of point estimates as *function estimators.*\n",
    "\n",
    "#### 4.2 Bias\n",
    "\n",
    "The bias of an estimator is deﬁned as:\n",
    "\n",
    "$$bias(θ_m) = E(θ_m) − θ,$$where E(θ) is the expected value of θ\n",
    "\n",
    "#### 4.3 Variance and Standard Error\n",
    "\n",
    "The variance of an estimator is simply the variance(var(θ)) and  the square root of this variance is called the standard error.\n",
    "\n",
    "For example standard error of the θ = mean is given by:\n",
    "\n",
    "$$SE(µ_m) =\\sqrt{Var\\left({1\\over m}\\sum^m_{i=1}x^{(i)}\\right)}={σ\\over\\sqrt{m}}$$\n",
    "\n",
    "#### 4.4 Trading oﬀ Bias and Variance to Minimize Mean Squared Error\n",
    "\n",
    "Bias and variance measure two diﬀerent sources of error in an estimator. \n",
    "<br>\n",
    "Bias measures the expected deviation from the true value of the function or parameter.\n",
    "<br>\n",
    "Variance on the other hand, provides a measure of the deviation from the expected estimator value that any particular sampling of the data is likely to cause.\n",
    "\n",
    "What happens when we are given a choice between two estimators, one with more bias and one with more variance? How do we choose between them?\n",
    "\n",
    "Let's Answer the question with a example plot for above solved case :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example Bias Variance trade off.....\n",
    "# Make sure you run the above code cell before this one since we are going to use values of above cell here...\n",
    "np.random.seed(7)\n",
    "# defining the test region\n",
    "te = 60\n",
    "tr = 80\n",
    "# fuction to return square of bias of the prediction\n",
    "def biasmean(ys,y):\n",
    "    return(np.mean((((y[0,te:tr]))-(ys[te:tr]))))**2\n",
    "\n",
    "# fuction to return variance of the prediction\n",
    "def biasvar(ys,y):\n",
    "    return(np.std(ys[te:tr]))**2\n",
    "\n",
    "\n",
    "bm = []\n",
    "bv = []\n",
    "ms = []\n",
    "\n",
    "# calculating values for already calculated values........................\n",
    "print(\"Plotting the variation of bias, variance ans MSE...\")\n",
    "for i in range(1,ys.shape[0]):\n",
    "    bm.append(biasmean(ys[i,:],ys[0,:].reshape(1,ys.shape[1])))\n",
    "    bv.append(biasvar(ys[i,:],ys[0,:].reshape(1,ys.shape[1])))\n",
    "\n",
    "    \n",
    "plt.figure(figsize=[16,8])\n",
    "plt.plot(np.flip(np.array(bm),axis=0)[:13],'-r',label=\"bias-square\")\n",
    "plt.plot(np.flip(np.array(bv),axis=0)[:13],'-k',label=\"variance\")\n",
    "plt.plot(np.flip(np.array(bv)+np.array(bm),axis=0)[:13],'-b',label=\"genrelization gap\")\n",
    "plt.plot(np.flip(np.array(cost),axis=0)[:13].reshape(13,1),'-y',label=\"loss function\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.axvline(x=9)\n",
    "plt.annotate('optimum capacity', xy=(9-1,0.6) )\n",
    "plt.annotate('overfitting\\nhigh variance', xy=(10,0.4) )\n",
    "plt.annotate('underfitting\\nhigh bias', xy=(9-4,0.5) )\n",
    "plt.title(\"Relation between bias variance and generalization gap\")\n",
    "plt.xlabel(\"Capacity (lambda descending)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> you will notice that optimization is directly related to bias and variance and obtained where the two are not very high or not very low so when you have trade off either bias or varience you should choos the optimal position by using such analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Consistency\n",
    "So far we have discussed the properties of various estimators for a training set of ﬁxed size. Usually, we are also concerned with the behavior of an estimator as the amount of training data grows.\n",
    "Consistency means as the number of examples increases the estimation converges to the actual estimation or actual solution.\n",
    "<br>\n",
    "Consistency ensures that the bias induced by the estimator diminishes as the number of data examples grows.\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Maximum Likelihood Estimation\n",
    "\n",
    "The question comes what are good estimators, basically we define estimmators based on some principles. One of the most generally used principle is maximum likelihood principle.\n",
    "\n",
    "Consider a set of m examples ***X = {x(1), . . . , x(m)}*** drawn independently fromthe true but unknown data-generating distribution ***pdata(x)***\n",
    "\n",
    "Let ***pmodel(x;θ)*** be a parametric family of probability distributions over thesame space indexed by ***θ***.\n",
    "\n",
    "The maximum likelihood estimator for θ is then deﬁned as:\n",
    "\n",
    "$$θ_{ML} = arg \\ max_θ\\ p_{model}(X; θ),\\\\= arg\\  max_θ\\ \\prod^m_{i=1}p_{model}(x^{(i)}; θ).$$applying log and scaling does not change the argument so we get,$$θ_{ML}= arg\\ max_θ{1\\over m}\\sum^m_{i=1}log p_{model}(x^{(i)}; θ)\\\\θ_{ML}= arg\\ max_θE_{x∼p_{data}}log p_{model}(x; θ)$$\n",
    "\n",
    "The degree of dissimilarity two models can be given by KL divergence:\n",
    "\n",
    "$$D_{KL}(p_{data}\\|p_{model}) = E_{x∼p_{data}}[log\\ p_{data}(x) − log\\ p_{model}(x)]$$\n",
    "\n",
    "minimizing this dissimilarity is same as maximizing the likely hood estimate...\n",
    "\n",
    "***cross-entropy***: Any loss consisting of a negative log-likelihood is a cross-entropy between the empirical distribution deﬁned by the training set and the probability distribution deﬁned by model.\n",
    "> For example, mean squared error is the cross-entropy between the empirical distribution and a Gaussian model.\n",
    "\n",
    "#### 5.1 Conditional Log-Likelihood and Mean Squared Error\n",
    "\n",
    "If X represents all our inputs and Y all our observed targets, then the conditional maximum likelihood estimator is:\n",
    "$$θ_{ML}= arg\\ max_θ\\ P (Y | X; θ).$$if examples are Independent and identically distributed(i.i.d):$$θ_{ML}= arg\\ max_θ\\ \\sum^m_{i=1}log\\ P (y^{(i)}|\\ x^{(i)}; θ).$$\n",
    "\n",
    "#### 5.2 Properties of Maximum Likelihood\n",
    "\n",
    "Under appropriate conditions, the maximum likelihood estimator has the property of ***consistency***:\n",
    "   - The true distribution pdata must lie within the model family pmodel.\n",
    "   - The true distribution pdata must correspond to exactly one value of θ.\n",
    "   \n",
    "That parametric mean squared error decreases as m (size of training data) increases, and for m large, the Cramér-Rao lower bound (Rao, 1945; Cramér, 1946) shows that no consistent estimator has a lower MSE than the maximum likelihood estimator.\n",
    "\n",
    "#### Example: Linear Regression as maximum likelyhood problem.....\n",
    "\n",
    "Since the examples are assumedto be i.i.d., the conditional log-likelihood is given by:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^mlog\\ p(y^{(i)}|\\ x^{(i)}; θ)\n",
    "=\n",
    "− m log(σ) −{m\\over2}log(2π) −\\sum^m_{i=1}{\\|y'(i)− y(i)\\|^2\\over{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "let's try to maximize it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example Linear Regression as maximum likely hood problem.\n",
    "np.random.seed(1)\n",
    "def cost(yd,y):\n",
    "    m = y.shape[0]\n",
    "    sigma = np.std(y)\n",
    "    \n",
    "    # YOUR CODE HERE \n",
    "    clld = None # calculate the maximum likelihood estimate from given equation as : \n",
    "    #-m*np.log(sigma) - (m/2)*np.log(2*np.pi) - np.dot((yd-y).T,(yd-y))/(2*(sigma**2))\n",
    "    # End\n",
    "    \n",
    "    return clld\n",
    "\n",
    "def d_cost(yd,y,x):\n",
    "    m = y.shape[0]\n",
    "    sigma = np.std(y)\n",
    "    dfdw = None # calculate the derivative of mlh equation w.r.t(w) as -->  -(0.5/sigma**2)*np.dot((yd-y).T,x)\n",
    "    dfdb = None # calculate the derivative of mlh equation w.r.t(b) as --> -(0.5/sigma**2)*np.sum((yd-y))\n",
    "    \n",
    "    return dfdw, dfdb\n",
    "    \n",
    "def regress(x,y,learning_rate):\n",
    "    w = np.random.randn(1,1)\n",
    "    b = np.random.randn(1,1)\n",
    "    yd = w*x + b\n",
    "    dcost = 10\n",
    "    ocost = 0\n",
    "    while(abs(dcost) > 0.00000001):\n",
    "        \n",
    "        dw, db = d_cost(yd,y,x)\n",
    "        \n",
    "        # YOUR CODE HERE \n",
    "        w = None # Update w to maximize the cost  use ---- > w + learning_rate*dw\n",
    "        b = None # Update b to maximize the cost  use ---- > b + learning_rate*db\n",
    "        # NOTE : we are using + instead of - to go up and maximize on the training surface\n",
    "        # End\n",
    "        \n",
    "        yd = w.T*x + b\n",
    "        ncost = cost(yd,y)\n",
    "        dcost = ncost - ocost\n",
    "        ocost = ncost\n",
    "        \n",
    "    return w, b\n",
    "\n",
    "x = np.random.randn(100,1)\n",
    "y = np.random.randn(100,1)**3\n",
    "w, b = regress(x,y,0.01)\n",
    "yd = w*x + b\n",
    "\n",
    "print(\"The figure denotes a regression line approximating the y with x\")\n",
    "plt.plot(x,yd,'-r')\n",
    "plt.plot(x,y,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected output :<br> The figure denotes a regression line approximating the y with x <img src = \"mlb/regression.png\"> NOTE: you got the same answer as previous linear regression example confirming the relation of maximum likelihood and mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bayesian Statistics\n",
    "\n",
    "So far we have discussed **frequentist statistics** and approaches based on estimating a single value of θ. Another approach is to consider all possible values of θ when making a prediction. The latter is the domain of **Bayesian statistics.**\n",
    "\n",
    "Unlike frequestist where the θ is fixed and unknown the bayesian uses probability to reﬂect degrees of certainty in states of knowledge.\n",
    "\n",
    "***Prior probability distribution***: Before observing the data, we represent our knowledge of θ using the prior probability distribution,p(θ) which in general choosen as one having quiet high entropy(quiet broad - high degree of uncertainity).\n",
    "\n",
    "And after that we observe the dataset to update the probability distribution according to dataset which gives optimized distribution which is nearly same as actual distribution.\n",
    "\n",
    "Consider we have data samples {x1,x2,.....,xm}. We can recover the eﬀect of data on our belief about θ by combining the data likelihood p(x1, . . . , xm| θ) with the prior via ***Bayes’ rule:***\n",
    "\n",
    "$$\n",
    "p(θ\\ |\\ x_1, . . . , x_m) ={p(x_1, . . . , x_m\\ |\\ θ).p(θ)\\over p(x_1, . . . , x_m)}\n",
    "$$\n",
    "\n",
    "In bayesian method after observing m examples, the predicted distribution over the next data sample, x(m+1), is given by:\n",
    "\n",
    "$$\n",
    "p(x_{m+1}\\ |\\ x_1, . . . , x_m) =\\int p(x_{m+1}\\ |\\ θ)\\ .p(θ\\ |\\ x_1, . . . , x_m) dθ\n",
    "$$\n",
    "\n",
    "benefits of bayesian:\n",
    "   - unlike the maximum likelihood approach that makes predictions using a point estimate of θ, the Bayesian approach is to make prediction using a full distribution over θ.\n",
    "   - the integral part tends to protect well against the overfitting which was taken care by variance in SPE.\n",
    "\n",
    "But still there are facts like: the prior has an inﬂuence by shifting probability mass density towards regions of the parameter space that are preferred a priori. Critics of the Bayesian approach identify the prior as a source of subjective human judgment aﬀecting the predictions. <br>Bayesian methods typically generalize much better when limited training data is available but typically suﬀer from high computational cost when the number of training examples is large.\n",
    "\n",
    "\n",
    "#### 6.1 Maximum a Posteriori (MAP) Estimation\n",
    "\n",
    "Single point estimates are easy to control(tractable) as compared to bayesian models. So in order to get bayesian benefits with a tractable model we allow the prior to inﬂuence the choice of the point estimate. One rational way to do this is to choose the **maximum a posteriori(MAP)** point estimate :\n",
    "\n",
    "$$\n",
    "θ_{MAP}= arg\\ max_θ\\ p(θ\\ |\\ x) = arg\\ max_θ\\ log\\ p(x\\ |\\ θ) + log\\ p(θ)\n",
    "$$\n",
    "\n",
    ">As an example, consider a linear regression model with a Gaussian prior on the weights **w**. If this prior is given by **N(w|0,(1/λ).I<sup>2</sup>)** *(a gaussian distribution with 0 mean and standard deviation as 1/λ)*, then the log-prior term is proportional to the familiar **λw<sup>T</sup>w** weight decay penalty, plus a term that does not depend on w and does not aﬀect the learning process. MAP Bayesian inference with a Gaussian prior on the weights thus corresponds to weight decay.\n",
    "\n",
    "One can say that MAP is a regularized Maximum likelyhood estimate.\n",
    "> Read more about it here : https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n",
    "\n",
    "#### Example: Bayesian Linear Regression.\n",
    "\n",
    "The prediction is parametrized as :\n",
    "$$y = w^T.x$$\n",
    "\n",
    "Given a set of m training samples (X(train), y(train)), we can express the prediction of y over the entire training set as:\n",
    "\n",
    "$$y_{(train)}= X_{(train)}.w$$\n",
    "\n",
    "Expressed as a Gaussian conditional distribution on y(train), we have:\n",
    "\n",
    "$$p(y_{(train)}| X_{(train)}, w) = N(y_{(train)}| X_{(train)}.w, I)\\\\∝ exp\\left({−1\\over2}(y_{(train)}− X_{(train)}.w)^T(y_{(train)}− X_{(train)}.w)\\right)$$ \n",
    "\n",
    "We need to define a prior distribution with high entropy.:\n",
    "\n",
    "$$\n",
    "p(w) = N(w\\ |\\ µ_0, Λ_0) ∝ exp\\left({−1\\over2}(w − µ_0)^TΛ^{−1}_0(w − µ_0)\\right)\n",
    "$$where µ<sub>0</sub> and Λ<sub>0</sub> are the prior distribution mean vector and covariance matrix respectively..\n",
    "\n",
    ">NOTE: Unless there is a reason to use a particular covariance structure, we typically assume a diagonal covariance matrix Λ<sub>0</sub>= diag(λ<sub>0</sub>).\n",
    "\n",
    "\n",
    "now proceed in determining the posterior distribution over the model parameters:\n",
    "\n",
    "$$\n",
    "p(w\\ |\\ X, y) ∝ p(y\\ |\\ X, w)\\ .p(w)\\\\\n",
    "∝ exp\\left({−1\\over2}(w − µ_0)^TΛ^{−1}_0(w − µ_0)\\right).exp\\left({−1\\over2}(y− X.w)^T(y− X.w)\\right)\\\\\n",
    "∝ exp\\left({−1\\over2}\\left(−2y^TXw + w^TX^TXw + w^TΛ^{−1}_0.w − 2µ^T_0Λ^{−1}_0.w\\right)\\right)\n",
    "$$\n",
    "we define,\n",
    "$$\n",
    "Λ_m=\\left(X^T.X + Λ^{−1}_0\\right)^{−1}; µ_m= Λ_m\\left(X^T.y + Λ^{−1}_0.µ_0\\right)\\\\\n",
    "∝ exp\\left({−1\\over2}(w − µ_m)^TΛ^{−1}_m.(w − µ_m) +{1\\over2}µ^T_m.Λ^{−1}_m.µ_m\\right)\\\\\n",
    "\\downarrow\\downarrow\\downarrow\\\\\n",
    "p(w\\ |\\ X, y)∝ exp\\left({−1\\over2}(w − µ_m)^TΛ^{−1}_m(w − µ_m)\\right)\n",
    "$$\n",
    "\n",
    "Examining this posterior distribution enables us to gain some intuition for the eﬀect of Bayesian inference. In most situations, we set µ<sub>0</sub> to 0. If we set Λ<sub>0</sub> = (1/α)I, then µ<sub>m</sub> gives the same estimate of was does frequentist linear regression with a weight decay penalty of αw<sup>T</sup>w. One diﬀerence is that the Bayesian estimate is undeﬁned if α is set to zero we are not allowed to begin the Bayesian learning process with an inﬁnitely wide prior on w. The more important diﬀerence is that the Bayesian estimate provides a covariance matrix, showing how likely all the diﬀerent values of w are, rather than providing only the estimate µ<sub>m</sub>.\n",
    "\n",
    "Let's try it out....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example Linear Regression as bayesian estimate problem.\n",
    "np.random.seed(1)\n",
    "xi = np.random.randn(100,1)\n",
    "y = np.random.randn(100,1)**3\n",
    "x = np.ones(xi.shape)\n",
    "x = np.append(x,xi,axis=1)\n",
    "\n",
    "def bayes_regress(x,y,alpha):\n",
    "    # alpha is equal to 1/variance\n",
    "    n = x.shape[1] # Rd d dimension of x\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    d0 = None # make a covariance matrix with alpha as 1/variance  use --> np.diag(np.ones((n))/alpha)\n",
    "    u0 = None # make a initial mean vector for prior  use -->  np.zeros((n,1)) \n",
    "    # END\n",
    "    \n",
    "    w = np.random.normal(0, np.sqrt(1/alpha), n) # initializing w's with prior guassian distribution\n",
    "    dm = inv(np.dot(x.T,x)+inv(d0)) # new integrated covarinace matrix dimension nxn\n",
    "    um = np.dot(dm,(np.dot(x.T,y)+np.dot(inv(d0),u0))) # final bayesian found weight distribution.\n",
    "    print(\"The weights by bayesian method are:\\n\",um)\n",
    "    \n",
    "    # Verifying the found result with the normal equations method(maximum likelihood estimation)\n",
    "    wmle = np.dot(inv(np.dot(x.T,x)),np.dot(x.T,y))\n",
    "    print(\"The weights by normal equation(MLE) method are:\\n\",wmle)\n",
    "    \n",
    "    return um\n",
    "    \n",
    "# A function to inverse nd.matrix    \n",
    "def inv(c):\n",
    "    m = c.shape[0]\n",
    "    if (m < 2):\n",
    "        return 1/c\n",
    "    else:\n",
    "        return np.linalg.inv(c)\n",
    "    \n",
    "# start of model computation...........    \n",
    "w = bayes_regress(x,y,0.01)     \n",
    "yd = np.dot(x,w)\n",
    "print(\"The figure denotes a regression line approximating the y with x\")\n",
    "plt.plot(xi,yd,'-r')\n",
    "plt.plot(xi,y,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected output:\n",
    "```\n",
    "The weights by bayesian method are:\n",
    " [[ 0.24069274]\n",
    " [ 0.42435956]]\n",
    "The weights by normal equation(MLE) method are:\n",
    " [[ 0.24071364]\n",
    " [ 0.42441186]]\n",
    "The figure denotes a regression line approximating the y with x\n",
    "```\n",
    "<img src = \"mlb/regression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Supervised Learning Algorithms\n",
    "\n",
    "Supervised learning algorithms are, roughly speaking, learning algorithms that learn to associate some input with some output, given a training set of examples of inputs x and outputs y.\n",
    "\n",
    "#### 7.1 Probabilistic Supervised Learning\n",
    "\n",
    "Most supervised learning algorithms in this book are based on estimating a probability distribution p(y | x). Linear regression is parameterized in terms of mean in real value domain but we can also talk about classes for example given a sample belons to class A or class B, 0 or 1 this type of regression is called logistic regression since we use sigmoid function to bound the probabilities in 0 to 1 range. Other function can also be used like tanh function.\n",
    "\n",
    "#### Logistic Regression:\n",
    "$$y' = \\sigma(w^T.x+b)\\\\sigmoid,\\sigma(x) = {1\\over (1+e^{-x})} $$\n",
    "\n",
    "since we are using sigmoid function the mean squared error no longer remains as convex and will not give optimal solution so we define new cost function using bernoulli's distribution since we are using binary classes:\n",
    "\n",
    "$$\n",
    "cost(y') = {\\begin{cases}-log(y')&{\\text{for }}y=1\\\\-log(1-y')&{\\text{for }}y=0\\end{cases}}\n",
    "$$net cost over m examples can be written as:$$\n",
    "J_{net-cost} = -{1\\over m}\\sum_i^my_ilogy'_i + (1-y_i)log(1-y'_i)\n",
    "$$\n",
    "\n",
    "here J is a convex function and so,\n",
    "now we can simply use gradient descent method over it. \n",
    "\n",
    ">NOTE: During prediction we say if y'(probability of being y=1) > 0.5 sample goes to class y = 1 else y = 0 class\n",
    "\n",
    "Let's give it a try:....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining problem run this cell...\n",
    "np.random.seed(12)\n",
    "x1 = np.abs(np.random.randn(100,1))\n",
    "x2_1 = 10*np.abs(np.random.randn(100,1))\n",
    "x2_2 = (x2_1) + 20 + np.random.randn(100,1)\n",
    "\n",
    "x_1 = np.append(x1,x2_1,axis=1)\n",
    "y_1 = np.ones((x_1.shape[0],1))\n",
    "x_2 = np.append(x1,x2_2,axis=1)\n",
    "y_2 = np.zeros((x_2.shape[0],1))\n",
    "\n",
    "x = np.append(x_1,x_2,axis=0)\n",
    "y = np.append(y_1,y_2,axis=0)\n",
    "\n",
    "print(\"yellow ones have class y = 0 and green ones have class y = 1\")\n",
    "plt.plot(x1,x2_1,'go')\n",
    "plt.plot(x1,x2_2,'yo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression model: Complete this part and run.......\n",
    "# defining the cost function\n",
    "np.random.seed(1)\n",
    "f, ax = plt.subplots(1,3,figsize=[16,4])\n",
    "def cost(y,yd):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    J = None # define cost as explained use --> (-1/m)*np.sum(y*np.log(yd) + (1-y)*np.log(1-yd))\n",
    "    # END\n",
    "    \n",
    "    return J\n",
    "\n",
    "def grads(y,yd,x):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    dw = None # calc diff of cost w.r.t w as --> (-1/m)*(np.dot(x.T,y*(1-yd)) - np.dot(x.T,(1-y)*yd))\n",
    "    db = None # calc diff of cost w.r.t b as --> (-1/m)*np.sum(y*(1-yd) - (1-y)*yd)\n",
    "    # End\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x)) # sigmoid function\n",
    "\n",
    "def logistic_reg(y,x,lr):\n",
    "    # similar to linear reression bus with different cost and grads\n",
    "    [m, n] = x.shape\n",
    "    mse = []\n",
    "    los = []\n",
    "    \n",
    "    # weights initializzation........\n",
    "    w = 0.01*np.random.randn(n,1)\n",
    "    b = 0.01*np.random.randn(1,1)\n",
    "    wmse = w # weight for mse error calc\n",
    "    bmse = b # bias for mse error calc\n",
    "\n",
    "    z = np.dot(x,w) + b\n",
    "    yd = sigmoid(z)\n",
    "    nc = cost(y,yd)\n",
    "    oc = nc\n",
    "    dc = 10\n",
    "    \n",
    "    while(abs(dc) > 0.0000001):\n",
    "        dw, db = grads(y,yd,x)\n",
    "        w = w - lr*dw\n",
    "        b = b - lr*db\n",
    "        yd = sigmoid(np.dot(x,w) + b)\n",
    "        nc = cost(y,yd)\n",
    "        dc = nc-oc\n",
    "        oc = nc\n",
    "        \n",
    "        los.append(nc)\n",
    "        \n",
    "        # Trying with mean squared loss.....on sigmoid function......\n",
    "        try:\n",
    "            ydmse = sigmoid(np.dot(x,wmse) + b)\n",
    "            dwmse = np.dot(x.T,(ydmse-y)*ydmse*(1-ydmse))\n",
    "            dbmse = np.sum((ydmse-y)*ydmse*(1-ydmse))/m\n",
    "            wmse = wmse - lr*dwmse\n",
    "            bmse = bmse - lr*dbmse\n",
    "            mse.append(0.5*np.dot((ydmse-y).T,ydmse-y)/m)\n",
    "        except error:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "    # plotting the error variation with number of epochs/ iterations\n",
    "    ax[0].plot(np.squeeze(mse).T)\n",
    "    ax[0].set_title(\"MSE error plot\")\n",
    "    ax[0].set_xlabel(\"number of iterations\")\n",
    "    ax[1].plot(np.squeeze(los).T)\n",
    "    ax[1].set_title(\"Logistic loss plot\")\n",
    "    ax[1].set_xlabel(\"number of iterations\")\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def predict(w,b,x):\n",
    "    return(sigmoid(np.dot(x,w) + b)>0.5)\n",
    "\n",
    "\n",
    "print(\"Training...\")    \n",
    "w, b = logistic_reg(y,x,0.05)\n",
    "yd  = predict(w,b,x)\n",
    "error = (np.sum(yd != y)/y.shape[0])*100\n",
    "print(\"Obtained Accuracy :\", 100 - error,\"%\")\n",
    "xerr1 = x[:,0].reshape(200,1)\n",
    "xerr2 = x[:,1].reshape(200,1)\n",
    "ax[2].plot(x1,x2_1,'go')\n",
    "ax[2].plot(x1,x2_2,'yo')\n",
    "ax[2].plot(xerr1[yd!=y],xerr2[yd!=y],'rs',alpha=0.7,label=\"wrong predictions\")\n",
    "ax[2].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Expected outptut :<br>\n",
    "    Obtained Accuracy : 97.0 %\n",
    "    <img src = \"mlb/logreg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Support Vector Machines\n",
    "\n",
    "One of the most inﬂuential approaches to supervised learning is the support vector machine.<br>\n",
    "We try to find a line for linear classification that separates the two class read below how:\n",
    "> For example the in linear kernel svm the hyper plane looks somthing like this:<img src=\"mlb/svm.jpg\"> The equation of hyperplane is nothing but **y = w*x + b**, so we say\n",
    "<br>\n",
    "*The main idea is to identify the optimal separating hyperplane which maximizes the margin of the training data.*\n",
    "prediction SVM:<br>\n",
    "    - f(x) = w.x + b\n",
    "    - if f(x) >= 1 --> y = 1\n",
    "    - if f(x) < -1 --> y = -1\n",
    "    -\n",
    "    - --> y.f(x) >= 1\n",
    "what we want is to maximize the marginal width between the 2 classes from seperation hyperplane. So if you try to find distcance from a point to a plane and then subtract the two distances you will get the margin and finally you will see that:\n",
    "<br>\n",
    "$$margin(m)∝{2\\over\\|w\\|}$$\n",
    "<br>\n",
    "so we need to minimize ||w|| given the constraint y.f(x) >= 1\n",
    "    <br>\n",
    "In many cases the data is not seperable properly so we introduce a slack variable..:\n",
    "<br>\n",
    "$$y_i.f(x)\\geq 1-\\zeta_i \\mbox{ for all } 1\\leq i \\leq n, \\zeta_i\\geq 0\\\\\\longrightarrow min\\ {\\|w\\|\\over2} + C\\sum{\\zeta_i}$$\n",
    "<br>this is called primal form, here just like lambda in regulization C can control the amount of regularization here...\n",
    "\n",
    "For non-linear SVMs we define it differently called the **dual form** transformation, we basically transform the space into high dmensional linearly seperable form and transform back after obtaining the result:\n",
    "<br>We know logistic regression uses sigmoid over:\n",
    "\n",
    "$$w^Tx + b = b +\\sum^m_{i=1}α_ix^Tx_{(i)}$$to give probability of a sample being in a class.\n",
    "\n",
    "SVM uses:\n",
    "\n",
    "$$f(x) = b +\\sum_{i}α_ik(x, x_{(i)})\\\\k(x, x_{(i)}) = \\phi(x)·\\phi(x_{(i)})$$<br>\n",
    "to classify samples directly being in a class or out of it by seeing the sign of output, where k is called a kernel function.<br>The most commonly used kernel is the ***Gaussian kernel***, also known as the ***radial basis function(RBF)*** kernel since it decreases along lines in v space radiating outward from u.\n",
    "\n",
    "$$k(u, v) = N(u − v; 0, σ^2.I)$$\n",
    "\n",
    "there are many other methods which can use kernels these methods are called kernel methods or ***kernel machines***. But kernel methods incorporates a high computational cost as compared to other methods but neural networks can out perform such kernel methods which we will discuss later.\n",
    "\n",
    "> Read more on kernel methods: https://en.wikipedia.org/wiki/Kernel_method\n",
    "\n",
    "Classification in SVM is based on vector's whose coefficent α is non_zero these are called ***support Vectors***.<br>\n",
    "To solve such transformmed problem of SVM we generally use another optimization algorithm called ***Sequential minimal optimization***, since the gradient descent will become very slow on larger datasets.\n",
    "> Read about Sequential minimal optimization here:https://en.wikipedia.org/wiki/Sequential_minimal_optimization and https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "\n",
    "We have our final dual form as:\n",
    "$$\n",
    "\\max _{\\alpha }\\sum _{i=1}^{n}\\alpha _{i}-{\\frac {1}{2}}\\sum _{i=1}^{n}\\sum _{j=1}^{n}y_{i}y_{j}K(x_{i},x_{j})\\alpha _{i}\\alpha _{j},\\\\\\text{\n",
    "subject to:}\\\\\n",
    "{\\displaystyle 0\\leq \\alpha _{i}\\leq C,\\quad {\\mbox{ for }}i=1,2,\\ldots ,n,}\\\\\n",
    "{\\displaystyle \\sum _{i=1}^{n}y_{i}\\alpha _{i}=0}\n",
    "$$\n",
    "\n",
    "> Duality or lagrange duality reference : https://en.wikipedia.org/wiki/Duality_(optimization)\n",
    "\n",
    "Let's try this...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining problem... run this cell\n",
    "# defining problem run this cell...\n",
    "np.random.seed(1)\n",
    "cx = (np.arange(0,100)-50)/10\n",
    "cy = np.sqrt(25 - cx**2)\n",
    "a = 0.8\n",
    "b = 1.5\n",
    "x1_1 = (a*cx - (np.random.randn(100))).reshape(100,1)\n",
    "x2_1 = (a*cy - (np.random.randn(100))).reshape(100,1)\n",
    "x1_2 = (b*cx + (np.random.randn(100))).reshape(100,1)\n",
    "x2_2 = (b*cy + (np.random.randn(100))).reshape(100,1)\n",
    "x_1 = np.append(x1_1,x2_1,axis=1)\n",
    "y_1 = np.ones((x_1.shape[0],1))\n",
    "x_2 = np.append(x1_2,x2_2,axis=1)\n",
    "y_2 = -np.ones((x_2.shape[0],1))\n",
    "x = np.append(x_1,x_2,axis=0)\n",
    "y = np.append(y_1,y_2,axis=0)\n",
    "print(\"yellow ones have class y = 0 and green ones have class y = 1\")\n",
    "plt.plot(x1_1,x2_1,'go')\n",
    "plt.plot(x1_2,x2_2,'yo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Supoport Vector Machine\n",
    "np.random.seed(1)\n",
    "def gkernel(x1, x2, sigma):\n",
    "    var = x1-x2\n",
    "    sim = np.exp(-(np.linalg.norm(var)**2)/(2*sigma**2))\n",
    "    return sim\n",
    "    \n",
    "def svm_train(X, Y, C,tol = 0.0001, max_passes=5):\n",
    "    [m, n] = X.shape\n",
    "    sigma = 0.1\n",
    "    \n",
    "    \n",
    "    # Variables\n",
    "    alpha = np.zeros((m,1))\n",
    "    b = 0\n",
    "    E = np.zeros((m, 1))\n",
    "    passes = 0\n",
    "    K = np.zeros((m,m))\n",
    "    eta = 0\n",
    "    L = 0\n",
    "    H = 0\n",
    "    \n",
    "    # The following can be slow due to the lack of vectorization\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            K[i,j] = gkernel(X[i,:], X[j,:],sigma)\n",
    "   \n",
    "\n",
    "\n",
    "    # Train\n",
    "    print('\\nTraining ...')\n",
    "    while (passes < max_passes):\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(m):\n",
    "            E[i] = b + np.sum (alpha*Y*K[:,i]) - Y[i]\n",
    "            \n",
    "            if ((Y[i]*E[i] < -tol and alpha[i] < C) or (Y[i]*E[i] > tol and alpha[i] > 0)):\n",
    "                j = i\n",
    "                while(j==i):\n",
    "                    j = np.random.randint(m)\n",
    "                \n",
    "                E[j] = b + np.sum (alpha*Y*K[:,j]) - Y[j]\n",
    "                \n",
    "                alpha_i_old = alpha[i]\n",
    "                alpha_j_old = alpha[j]\n",
    "                \n",
    "                # L is the lower and H is Higher bounds on alpha to be changed\n",
    "                if (Y[i] == Y[j]): # alpha[j] + alpha[i] > C\n",
    "                    L = max(0, alpha[j] + alpha[i] - C) \n",
    "                    H = min(C, alpha[j] + alpha[i])\n",
    "                else: # alpha[j] > alpha[i]\n",
    "                    L = max(0, alpha[j] - alpha[i])\n",
    "                    H = min(C, C + alpha[j] - alpha[i])\n",
    "                \n",
    "                if (L == H): # if alphas are zero or C\n",
    "                    continue\n",
    "                    \n",
    "                eta = 2 * K[i,j] - K[i,i] - K[j,j] # if the kernels are too close\n",
    "                if (eta >= 0):\n",
    "                    continue\n",
    "                \n",
    "                alpha[j] = alpha[j] - (Y[j] * (E[i] - E[j])) / eta # update of alpha[j]\n",
    "                \n",
    "                # contraints  alpha > 0 and < C\n",
    "                alpha[j] = min (H, alpha[j])\n",
    "                alpha[j] = max (L, alpha[j])\n",
    "                \n",
    "                # check if change in alpha is significant:\n",
    "                if (abs(alpha[j] - alpha_j_old) < tol):\n",
    "                    alpha[j] = alpha_j_old\n",
    "                    continue\n",
    "                    \n",
    "                # Determine value for alpha i  \n",
    "                alpha[i] = alpha[i] + Y[i]*Y[j]*(alpha_j_old - alpha[j])\n",
    "                \n",
    "                # computing b\n",
    "                b1 = b - E[i] - Y[i]*(alpha[i]-alpha_i_old)*K[i,j]-Y[j]*(alpha[j]-alpha_j_old)*K[i,i]\n",
    "                b2 = b - E[j] - Y[i]*(alpha[i]-alpha_i_old)*K[i,j]-Y[j]*(alpha[j]-alpha_j_old)*K[j,j]    \n",
    "                \n",
    "                if(0<alpha[i] and alpha[i]<C):\n",
    "                    b = b1\n",
    "                elif(0<alpha[j] and alpha[j]<C):\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2)/2\n",
    "                \n",
    "                num_changed_alphas = num_changed_alphas + 1\n",
    "                \n",
    "        \n",
    "        if(num_changed_alphas==0):\n",
    "            passes = passes+1\n",
    "        else:\n",
    "            passes = 0\n",
    "        \n",
    "    print(\"Done\")\n",
    "    \n",
    "    return K, b, alpha\n",
    "\n",
    "def predict_svm(K,b,alpha,X,Y):   \n",
    "    # prediction\n",
    "    [m, n] = X.shape\n",
    "    Yd = Y*0\n",
    "    for i in range(m):\n",
    "        Pr = 0\n",
    "        for j in range(m):\n",
    "            Pr = Pr + alpha[j]*Y[j]*K[i,j]\n",
    "        Yd[i] = Pr + b\n",
    "    \n",
    "    Yd[Yd>=0] = 1\n",
    "    Yd[Yd<0] = -1\n",
    "    \n",
    "    return Yd\n",
    "    \n",
    "                \n",
    "                \n",
    "                \n",
    "C = 50\n",
    "K, b, alpha = svm_train(x,y,C)\n",
    "yd = predict_svm(K, b, alpha, x, y)\n",
    "\n",
    "accuracy = 100*(np.sum(yd==y)/yd.shape[0])\n",
    "print(\"Accuracy:\",accuracy,\"%\")\n",
    "xm1 = x[:,0].reshape(200,1)\n",
    "xm2 = x[:,1].reshape(200,1)\n",
    "x1 = xm1[yd!=y]\n",
    "x2 = xm2[yd!=y]\n",
    "\n",
    "plt.figure(figsize=[16,8])\n",
    "plt.plot(x1_1,x2_1,'bo')\n",
    "plt.plot(x1_2,x2_2,'ko')\n",
    "plt.plot(x1,x2,'ro',label=\"misclassifications\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> You can read about implentation of SMO in detail here: http://pages.cs.wisc.edu/~dpage/cs760/SMOlecture.pdf\n",
    "\n",
    "#### 7.3 Other Simple Supervised Learning Algorithms\n",
    "\n",
    "There are also some non probabilistic algorithms like:\n",
    "\n",
    "** K - Nearest Neighbour **: is a family of techniques that can be used for regression or classification. As a non parametric learning algorithm, k-nearest neighbors is not restricted to a ﬁxed number of parameters. When we want to produce an output y for a new test input x, we ﬁnd the k-nearest neighbours to x in the training data X. We then return the average of the corresponding y values in the training set. This works for essentially any kind of supervised learning where we can deﬁne an average over y values.\n",
    "\n",
    "> Algorithm:\n",
    "    - Calc distance of test vector from all training vector\n",
    "    - Sort the distances\n",
    "    - pick k nearest training vectors(neighbours).\n",
    "    - classify test vector to majority among the k neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining problem run this cell...\n",
    "np.random.seed(12)\n",
    "x1 = np.abs(np.random.randn(100,1))\n",
    "x2_1 = 10*np.abs(np.random.randn(100,1))\n",
    "x2_2 = (x2_1) + 16 + np.random.randn(100,1)\n",
    "x_1 = np.append(x1,x2_1,axis=1)\n",
    "y_1 = np.ones((x_1.shape[0],1))\n",
    "x_2 = np.append(x1,x2_2,axis=1)\n",
    "y_2 = np.zeros((x_2.shape[0],1))\n",
    "x = np.append(x_1,x_2,axis=0)\n",
    "y = np.append(y_1,y_2,axis=0)\n",
    "print(\"yellow ones have class y = 0 and green ones have class y = 1\")\n",
    "plt.plot(x1,x2_1,'go')\n",
    "plt.plot(x1,x2_2,'yo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K- nearest neighbours: Classification\n",
    "def findClass(x,y,point,k):\n",
    "    [m, n] = x.shape\n",
    "    dist = y*0\n",
    "    for i in range(m):\n",
    "        d = 0\n",
    "        for j in range(n):\n",
    "            d = d + (x[i,j] - point[j])**2\n",
    "        \n",
    "        dist[i] = np.sqrt(d)\n",
    "    \n",
    "    indx = np.argsort(dist,axis=0)\n",
    "    \n",
    "    dist = dist[indx]\n",
    "    y = y[indx]\n",
    "    \n",
    "    c = 0\n",
    "    for i in range(k):\n",
    "        c = c + y[i]\n",
    "        \n",
    "    c = c/k\n",
    "    c = 1*(c>0.5)\n",
    "\n",
    "    return c\n",
    "\n",
    "def classify(x,y,test,k):\n",
    "    \n",
    "    m = test.shape[0]\n",
    "    yd = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        yd[i] = findClass(x,y,test[i,:],k)\n",
    "        \n",
    "    return yd\n",
    "    \n",
    "    \n",
    "    \n",
    "percent = 0.8\n",
    "trs = int(percent*y.shape[0])\n",
    "x_tr = x[0:trs] \n",
    "y_tr = y[0:trs]\n",
    "x_te = x[trs:]\n",
    "y_te = y[trs:]\n",
    "\n",
    "K = 3 # try changing this value\n",
    "\n",
    "yd = classify(x_tr,y_tr,x_te,K)\n",
    "A = (yd==y_te)\n",
    "acc = 100*np.sum(A)/A.shape[0]\n",
    "print(\"Accuracy :\",acc,\"%\")\n",
    "\n",
    "plt.plot(x1,x2_1,'go')\n",
    "plt.plot(x1,x2_2,'yo')\n",
    "m1 = x[trs:,0].reshape(y.shape[0]-trs,1)[yd!=y_te]\n",
    "m2 = x[trs:,1].reshape(y.shape[0]-trs,1)[yd!=y_te]\n",
    "plt.plot(m1,m2,'r^',label = 'missclassified')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There are some other non parametric methods like decision trees which you can read here if you want: https://en.wikipedia.org/wiki/Decision_tree_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Unsupervised Learning Algorithms\n",
    "\n",
    "As we already discussed unsupervised learning are the type of learning in which the output label is not provided and so the learning is done purely based on input data and so we can't really distinguish between the two that efficiently. In general these are used to find the best representaion of data available.\n",
    "\n",
    "There are multiple ways of deﬁning a simpler representation:\n",
    "   - lower-dimensional representations\n",
    "   - sparse representations\n",
    "   - independent representations\n",
    "   \n",
    "There are several popular methods for doing this:\n",
    "\n",
    "#### 8.1 PCA (principal component analysis)\n",
    "As we discussed already in Linear Algebra PCA is used for dimensional reduction i.e lower dimensional representaion.\n",
    "\n",
    "#### 8.2 K-means Clustering\n",
    "The k-means clustering algorithm divides the training set into k diﬀerent clusters of examples that are near each other.\n",
    "We can thus think of the algorithm as providing a k-dimensional one-hot code vector h representing an input x.\n",
    "\n",
    "> One-hot Code : https://en.wikipedia.org/wiki/One-hot\n",
    "\n",
    "The one-hot code provided by k-means clustering is an example of a sparse representation, because the majority of its entries are zero for every input, where more than one entry can be nonzero for each input x. One-hot codes are an extreme example of sparse representations that lose many of the beneﬁts of a distributed representation. The one-hot code still confers some statistical advantages, and it confers the computational advantage that the entire representation may be captured by a single integer.\n",
    "\n",
    "Algorithm: -\n",
    "\n",
    "   1. Given a set of inputs {x1,x2,x3,x4.....,xn} x has d dimensions, and a number k defining the number of clusters to form.\n",
    "   2. Inintialize K centroids all of them as far as possible from each other in d dimneisonal space near to inputs.\n",
    "   3. Calculate the distance of each sample from each centroid and assign it to minimum distance cluster centroid.\n",
    "   4. take average of the clusters and update the centroid to new averaged centroid.\n",
    "   5. repeat steps 3 to 5 till convergence.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Representing Iniitial data\n",
    "np.random.seed(50)\n",
    "x = np.random.rand(300,2)\n",
    "x[0:150,0] = x[0:150,0] + 1 + np.random.rand(150,)\n",
    "x[0:150,1] = x[0:150,1] + 1 - np.random.rand(150,)\n",
    "x[150:200,0] = x[150:200,0]*1 + 2*np.random.rand(50,)\n",
    "x[150:200,1] = x[150:200,1]*2 + np.random.rand(50,)\n",
    "plt.plot(x[:,0],x[:,1],'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K - means Clustering\n",
    "np.random.seed(12)\n",
    "plt.figure(figsize=[16,8])\n",
    "def cluster(x,k,max_pass=5):\n",
    "    [m, n] = x.shape\n",
    "    C = np.random.rand(k, n)\n",
    "    d = np.zeros((m,k))\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(n):\n",
    "            d[:,i] = d[:,i] + (x[:,j] - C[i,j])**2\n",
    "            \n",
    "    oh = np.argmin(d,axis=1)\n",
    "    oldoh = oh*0\n",
    "    d = np.zeros((m,k))\n",
    "    ghi = 0\n",
    "    cp = C.reshape(C.shape[0],C.shape[1],1)\n",
    "    passes = 0\n",
    "    while(passes < max_pass):\n",
    "        for z in range(k):\n",
    "            mask = (oh==z).reshape(m,1)*1\n",
    "            div = np.sum(mask)\n",
    "            xd = x*mask\n",
    "            if (div!=0):\n",
    "                C[z,:] = np.sum(xd,axis=0)/div\n",
    "        \n",
    "        for i in range(k):\n",
    "            for j in range(n):\n",
    "                d[:,i] = d[:,i] + (x[:,j] - C[i,j])**2\n",
    "        \n",
    "        oldoh = oh\n",
    "        oh = np.argmin(d,axis=1)\n",
    "        d = np.zeros((m,k))\n",
    "        ghi = ghi+1\n",
    "        \n",
    "        if(np.sum(oldoh != oh)<=1):\n",
    "            passes = passes+1\n",
    "        else:\n",
    "            passes = 0\n",
    "        \n",
    "        cp= np.append(cp,C.reshape(k,n,1),axis = 2)\n",
    "        \n",
    "    for i in range(k):\n",
    "        if (i == 0):\n",
    "            plt.plot(cp[i,0,:],cp[i,1,:],'-kx',label=\"path of centroids\")\n",
    "        else:\n",
    "            plt.plot(cp[i,0,:],cp[i,1,:],'-kx')\n",
    "    \n",
    "    \n",
    "    return C, oh.reshape(m)\n",
    "\n",
    "        \n",
    "C, h = cluster(x,2)    \n",
    "plt.scatter(x[:,0],x[:,1],c = h)\n",
    "plt.plot(C[:,0],C[:,1],'ro',label=\"centroid\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Stochastic Gradient Descent\n",
    "\n",
    "When the data size increases the computation time for one iteration increases in gradient descent and in many other optimization models due to which the optimation process becomes very slow.\n",
    "\n",
    "***Stochastic means random***, we basically shuffle and divide the training data into ***minibatches*** of fast computable sample sets this does not go directly down the slope of actual cost function since we are considering only some data but on a average over few iteration you will see that it goes towards the optimal location. one problem might come during convergence which may result in very small fluctuations but no convergence so we have to stop iterating at that time.\n",
    "\n",
    "The convergence path over cost contour plot will look something like this : <img src=\"mlb/stochastic.png\">\n",
    "\n",
    "For more details about stochastic gradient descent go here : https://en.wikipedia.org/wiki/Stochastic_gradient_descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "### 10. Building a Machine Learning Algorithm\n",
    "\n",
    "Nearly all deep learning algorithms can be described as particular instances of a fairly simple recipe: combine a speciﬁcation of a dataset, a cost function, an optimization procedure and a model.\n",
    "\n",
    "> Example: Linear Regression \n",
    "``` \n",
    "- specification of data --> {X,y}\n",
    "- cost function --> J(w, b) = −Ex,y∼ˆpdatalog pmodel(y | x),\n",
    "- model specification --> p(Y|X) = N(y|x'.w+b,1)\n",
    "```\n",
    "\n",
    "By realizing that we can replace any of these components mostly independently from the others, we can obtain a wide range of algorithms.\n",
    "\n",
    "The recipe for constructing a learning algorithm by combining models, costs, andoptimization algorithms supports both supervised and unsupervised learning.\n",
    "\n",
    "Unsupervised learning can be supported by deﬁning a dataset that contains only X and providing an appropriate unsupervised cost and model:\n",
    ">Example: PCA can be modeled as:\n",
    "<br>\n",
    "    - specification of data --> {X}<br>\n",
    "    - cost function --> J(w) = Ex∼pdata||x − r(x; w)||^2\n",
    "    - model specisification r(x) = (w.T).x.(w)\n",
    "\n",
    "In some cases, the cost function may be a function that we cannot actually evaluate, for computational reasons. In these cases, we can still approximately minimize it using iterative numerical optimization, as long as we have some way of approximating its gradients.\n",
    "\n",
    "> Please read section 5.10 here: http://www.deeplearningbook.org/contents/ml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### 11. Challenges Motivating Deep Learning\n",
    "\n",
    "> Please read section 5.11 here: http://www.deeplearningbook.org/contents/ml.html\n",
    "\n",
    "**# Congratulation #** on Completing this large tutorial you have learned alot of useful machine learning approaches and techniques. there are alot more but those are alos related to what you have already learned tap on your back and move forward to part 2 of this series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
